{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 브런치 사용자를 위한 작가 및 글 추천\n",
    "## 1팀 : AI Love You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import timedelta, datetime\n",
    "import glob\n",
    "from itertools import chain\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib import font_manager, rc # rc == run configure(configuration file)\n",
    "\n",
    "%matplotlib inline\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\", size=10).get_name()\n",
    "# rc('font', family=font_name, size=12)\n",
    "\n",
    "# font_path = 'NanumGothic.ttf'\n",
    "# font_name = fm.FontProperties(fname=font_path, size=10).get_name()\n",
    "plt.rc('font', family=font_name, size=12)\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/jisoo/python_MLDL/Mid_Project/mid_ailoveu_temp/brunch_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magazine_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>keyword_list</th>\n",
       "      <th>display_url</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>reg_ts</th>\n",
       "      <th>article_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8982</td>\n",
       "      <td>@bookdb</td>\n",
       "      <td>사진으로 옮기기에도 아까운, 리치필드 국립공원</td>\n",
       "      <td>[여행, 호주, 국립공원]</td>\n",
       "      <td>https://brunch.co.kr/@bookdb/782</td>\n",
       "      <td>세상 어디에도 없는 호주 Top 10</td>\n",
       "      <td>1474944427000</td>\n",
       "      <td>782</td>\n",
       "      <td>@bookdb_782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12081</td>\n",
       "      <td>@kohwang56</td>\n",
       "      <td>[시] 서러운 봄</td>\n",
       "      <td>[목련꽃, 아지랑이, 동행]</td>\n",
       "      <td>https://brunch.co.kr/@kohwang56/81</td>\n",
       "      <td></td>\n",
       "      <td>1463092749000</td>\n",
       "      <td>81</td>\n",
       "      <td>@kohwang56_81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@hannahajink</td>\n",
       "      <td>무엇을 위해</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://brunch.co.kr/@hannahajink/4</td>\n",
       "      <td>무엇 때문에</td>\n",
       "      <td>1447997287000</td>\n",
       "      <td>4</td>\n",
       "      <td>@hannahajink_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16315</td>\n",
       "      <td>@bryceandjuli</td>\n",
       "      <td>싫다</td>\n",
       "      <td>[감정, 마음, 위로]</td>\n",
       "      <td>https://brunch.co.kr/@bryceandjuli/88</td>\n",
       "      <td></td>\n",
       "      <td>1491055161000</td>\n",
       "      <td>88</td>\n",
       "      <td>@bryceandjuli_88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29363</td>\n",
       "      <td>@mijeongpark</td>\n",
       "      <td>Dubliner#7</td>\n",
       "      <td>[유럽여행, 더블린, 아일랜드]</td>\n",
       "      <td>https://brunch.co.kr/@mijeongpark/34</td>\n",
       "      <td>#7. 내 친구의 집은 어디인가</td>\n",
       "      <td>1523292942000</td>\n",
       "      <td>34</td>\n",
       "      <td>@mijeongpark_34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   magazine_id        user_id                      title       keyword_list  \\\n",
       "0         8982        @bookdb  사진으로 옮기기에도 아까운, 리치필드 국립공원     [여행, 호주, 국립공원]   \n",
       "1        12081     @kohwang56                  [시] 서러운 봄    [목련꽃, 아지랑이, 동행]   \n",
       "2            0   @hannahajink                     무엇을 위해                 []   \n",
       "3        16315  @bryceandjuli                         싫다       [감정, 마음, 위로]   \n",
       "4        29363   @mijeongpark                 Dubliner#7  [유럽여행, 더블린, 아일랜드]   \n",
       "\n",
       "                             display_url             sub_title         reg_ts  \\\n",
       "0       https://brunch.co.kr/@bookdb/782  세상 어디에도 없는 호주 Top 10  1474944427000   \n",
       "1     https://brunch.co.kr/@kohwang56/81                        1463092749000   \n",
       "2    https://brunch.co.kr/@hannahajink/4                무엇 때문에  1447997287000   \n",
       "3  https://brunch.co.kr/@bryceandjuli/88                        1491055161000   \n",
       "4   https://brunch.co.kr/@mijeongpark/34     #7. 내 친구의 집은 어디인가  1523292942000   \n",
       "\n",
       "   article_id                id  \n",
       "0         782       @bookdb_782  \n",
       "1          81     @kohwang56_81  \n",
       "2           4    @hannahajink_4  \n",
       "3          88  @bryceandjuli_88  \n",
       "4          34   @mijeongpark_34  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_json('metadata.json', lines=True)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. user_keyword.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = pd.read_excel('user_keyword.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>keyword_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#00001ba6ca8d87d2fc34d626ba9cfe6f</td>\n",
       "      <td>['사랑', '성공', '인생', '브런치', '작가', '글쓰기', '해외취업',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#0000e87158c1426d6ffb72cebac6cb64</td>\n",
       "      <td>['브런치', '가해자', '여성혐오', '페미니스트']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#0000eea6d339abfd02ed590bc451fc63</td>\n",
       "      <td>['인간관계', '해외생활', '회사']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#0000fdba8f35c76eacab74c5c6bc7f1a</td>\n",
       "      <td>['도쿄', '여행', '그림에세이', '도쿄', '여행', '그림에세이', '운동...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#000127ad0f1981cae1292efdb228f0e9</td>\n",
       "      <td>['사랑', '결혼', '결혼생활', '사랑', '결혼', '결혼생활', '연애',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id  \\\n",
       "0  #00001ba6ca8d87d2fc34d626ba9cfe6f   \n",
       "1  #0000e87158c1426d6ffb72cebac6cb64   \n",
       "2  #0000eea6d339abfd02ed590bc451fc63   \n",
       "3  #0000fdba8f35c76eacab74c5c6bc7f1a   \n",
       "4  #000127ad0f1981cae1292efdb228f0e9   \n",
       "\n",
       "                                        keyword_list  \n",
       "0  ['사랑', '성공', '인생', '브런치', '작가', '글쓰기', '해외취업',...  \n",
       "1                    ['브런치', '가해자', '여성혐오', '페미니스트']  \n",
       "2                             ['인간관계', '해외생활', '회사']  \n",
       "3  ['도쿄', '여행', '그림에세이', '도쿄', '여행', '그림에세이', '운동...  \n",
       "4  ['사랑', '결혼', '결혼생활', '사랑', '결혼', '결혼생활', '연애',...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. writer.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_4000 = pd.read_csv('writer_4000most320_keyword_keywords.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer_4000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer_id</th>\n",
       "      <th>page_num</th>\n",
       "      <th>keyword_list</th>\n",
       "      <th>keyword_list_20</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@bookfit</td>\n",
       "      <td>4106</td>\n",
       "      <td>['성공', '행복', '인생']</td>\n",
       "      <td>['성공', '행복', '인생', '부동산', '여행', '창업', '사랑', '생...</td>\n",
       "      <td>['창업', '비즈니스', '문제', '경제', '살림살이', '경제학', '미세먼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@wikitree</td>\n",
       "      <td>3192</td>\n",
       "      <td>['영화', '뉴스', '연합뉴스']</td>\n",
       "      <td>['영화', '뉴스', '연합뉴스', '경찰', '다이어트', '사진', '여행',...</td>\n",
       "      <td>['지휘관', '장교', '청계천', '서울', 'IT', '번호', '중소기업',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@jordan777</td>\n",
       "      <td>2797</td>\n",
       "      <td>['중국', '미국', '트럼프']</td>\n",
       "      <td>['중국', '미국', '트럼프', '부동산', '주식', '투자', '구글', '...</td>\n",
       "      <td>['석유에너지', '베네수엘라', '경제', '일자리', '청년실업', '저출산',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@hitchwill</td>\n",
       "      <td>2115</td>\n",
       "      <td>['국내여행', '영화', '여행']</td>\n",
       "      <td>['국내여행', '영화', '여행', '여행정보', '음식', '사랑', '소설',...</td>\n",
       "      <td>['국내여행', '한옥', '청양', '여행', '가을', '코스모스', '감귤농장...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@tenbody</td>\n",
       "      <td>1759</td>\n",
       "      <td>['다이어트', '운동', '건강']</td>\n",
       "      <td>['다이어트', '운동', '건강', '스트레칭', '근육', '뱃살', '요가',...</td>\n",
       "      <td>['운동', '근육', '다이어트', '운동', '뱃살', '다이어트', '운동',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    writer_id  page_num          keyword_list  \\\n",
       "0    @bookfit      4106    ['성공', '행복', '인생']   \n",
       "1   @wikitree      3192  ['영화', '뉴스', '연합뉴스']   \n",
       "2  @jordan777      2797   ['중국', '미국', '트럼프']   \n",
       "3  @hitchwill      2115  ['국내여행', '영화', '여행']   \n",
       "4    @tenbody      1759  ['다이어트', '운동', '건강']   \n",
       "\n",
       "                                     keyword_list_20  \\\n",
       "0  ['성공', '행복', '인생', '부동산', '여행', '창업', '사랑', '생...   \n",
       "1  ['영화', '뉴스', '연합뉴스', '경찰', '다이어트', '사진', '여행',...   \n",
       "2  ['중국', '미국', '트럼프', '부동산', '주식', '투자', '구글', '...   \n",
       "3  ['국내여행', '영화', '여행', '여행정보', '음식', '사랑', '소설',...   \n",
       "4  ['다이어트', '운동', '건강', '스트레칭', '근육', '뱃살', '요가',...   \n",
       "\n",
       "                                            keywords  \n",
       "0  ['창업', '비즈니스', '문제', '경제', '살림살이', '경제학', '미세먼...  \n",
       "1  ['지휘관', '장교', '청계천', '서울', 'IT', '번호', '중소기업',...  \n",
       "2  ['석유에너지', '베네수엘라', '경제', '일자리', '청년실업', '저출산',...  \n",
       "3  ['국내여행', '한옥', '청양', '여행', '가을', '코스모스', '감귤농장...  \n",
       "4  ['운동', '근육', '다이어트', '운동', '뱃살', '다이어트', '운동',...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer_4000.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. users.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_follow = pd.read_json('users.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following_list가 있는 유저\n",
    "following = users_follow[users_follow['following_list'].str.len() !=0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>following_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#901985d8bc4c481805c4a4f911814c4a</td>\n",
       "      <td>[@perytail, @brunch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#1fd89e9dcfa64b45020d9eaca54e0eed</td>\n",
       "      <td>[@holidaymemories, @wadiz, @sciforus, @dailydu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#1d94baaea71a831e1f33e1c6bd126ed5</td>\n",
       "      <td>[@commerceguy, @sunsutu, @kakao-it, @joohoonja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#04641c01892b12dc018b1410e4928c0d</td>\n",
       "      <td>[@amberjeon48, @forsy20, @nemotokki, @hawann, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#65bcaff862aadff877e461f54187ab62</td>\n",
       "      <td>[@dwcha7342, @iammento, @kakao-it, @dkam, @ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310752</th>\n",
       "      <td>#6b7a58c1002fe2763bf4db6e223769b1</td>\n",
       "      <td>[@angiesongc9sx, @merryseo, @psychiatricnews, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310753</th>\n",
       "      <td>#2863e47d50f1640df6dac10b7bad94fb</td>\n",
       "      <td>[@login002, @kkonal, @leeraha, @tobeme, @sohyu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310754</th>\n",
       "      <td>#4341a155d1966e5618e310c45386aea4</td>\n",
       "      <td>[@simplelife-1p, @mint5051, @thecapitalist, @s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310755</th>\n",
       "      <td>#0d70f397a78d2ef638f812592fa8e6ba</td>\n",
       "      <td>[@cometseeker, @bijou, @suhanjang, @brunch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310756</th>\n",
       "      <td>#1bbf5e3d1e4c373103981cdd819812da</td>\n",
       "      <td>[@taekangk, @cielbleu, @yongisa, @joongheekim,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303490 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  \\\n",
       "0       #901985d8bc4c481805c4a4f911814c4a   \n",
       "1       #1fd89e9dcfa64b45020d9eaca54e0eed   \n",
       "2       #1d94baaea71a831e1f33e1c6bd126ed5   \n",
       "3       #04641c01892b12dc018b1410e4928c0d   \n",
       "4       #65bcaff862aadff877e461f54187ab62   \n",
       "...                                   ...   \n",
       "310752  #6b7a58c1002fe2763bf4db6e223769b1   \n",
       "310753  #2863e47d50f1640df6dac10b7bad94fb   \n",
       "310754  #4341a155d1966e5618e310c45386aea4   \n",
       "310755  #0d70f397a78d2ef638f812592fa8e6ba   \n",
       "310756  #1bbf5e3d1e4c373103981cdd819812da   \n",
       "\n",
       "                                           following_list  \n",
       "0                                    [@perytail, @brunch]  \n",
       "1       [@holidaymemories, @wadiz, @sciforus, @dailydu...  \n",
       "2       [@commerceguy, @sunsutu, @kakao-it, @joohoonja...  \n",
       "3       [@amberjeon48, @forsy20, @nemotokki, @hawann, ...  \n",
       "4       [@dwcha7342, @iammento, @kakao-it, @dkam, @ant...  \n",
       "...                                                   ...  \n",
       "310752  [@angiesongc9sx, @merryseo, @psychiatricnews, ...  \n",
       "310753  [@login002, @kkonal, @leeraha, @tobeme, @sohyu...  \n",
       "310754  [@simplelife-1p, @mint5051, @thecapitalist, @s...  \n",
       "310755        [@cometseeker, @bijou, @suhanjang, @brunch]  \n",
       "310756  [@taekangk, @cielbleu, @yongisa, @joongheekim,...  \n",
       "\n",
       "[303490 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "following = following[['id', 'following_list']]\n",
    "following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer_id</th>\n",
       "      <th>page_num</th>\n",
       "      <th>keyword_list</th>\n",
       "      <th>keyword_list_20</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@bookfit</td>\n",
       "      <td>4106</td>\n",
       "      <td>['성공', '행복', '인생']</td>\n",
       "      <td>['성공', '행복', '인생', '부동산', '여행', '창업', '사랑', '생...</td>\n",
       "      <td>['창업', '비즈니스', '문제', '경제', '살림살이', '경제학', '미세먼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@wikitree</td>\n",
       "      <td>3192</td>\n",
       "      <td>['영화', '뉴스', '연합뉴스']</td>\n",
       "      <td>['영화', '뉴스', '연합뉴스', '경찰', '다이어트', '사진', '여행',...</td>\n",
       "      <td>['지휘관', '장교', '청계천', '서울', 'IT', '번호', '중소기업',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@jordan777</td>\n",
       "      <td>2797</td>\n",
       "      <td>['중국', '미국', '트럼프']</td>\n",
       "      <td>['중국', '미국', '트럼프', '부동산', '주식', '투자', '구글', '...</td>\n",
       "      <td>['석유에너지', '베네수엘라', '경제', '일자리', '청년실업', '저출산',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@hitchwill</td>\n",
       "      <td>2115</td>\n",
       "      <td>['국내여행', '영화', '여행']</td>\n",
       "      <td>['국내여행', '영화', '여행', '여행정보', '음식', '사랑', '소설',...</td>\n",
       "      <td>['국내여행', '한옥', '청양', '여행', '가을', '코스모스', '감귤농장...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@tenbody</td>\n",
       "      <td>1759</td>\n",
       "      <td>['다이어트', '운동', '건강']</td>\n",
       "      <td>['다이어트', '운동', '건강', '스트레칭', '근육', '뱃살', '요가',...</td>\n",
       "      <td>['운동', '근육', '다이어트', '운동', '뱃살', '다이어트', '운동',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>@starshines</td>\n",
       "      <td>39</td>\n",
       "      <td>['영화', '사랑', '전쟁']</td>\n",
       "      <td>['영화', '사랑', '전쟁', '범죄영화', '픽사', '리뷰', '한국영화',...</td>\n",
       "      <td>['영화', '저니스엔드', '전쟁', '영화', '하정우', '민주주의', '히트...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>@jeolmiing</td>\n",
       "      <td>39</td>\n",
       "      <td>['독서', '독서모임', '인터뷰']</td>\n",
       "      <td>['독서', '독서모임', '인터뷰', '사랑', '모임', '행복', '생각', ...</td>\n",
       "      <td>['독서', '일상', '인터뷰', '후기', '독서모임', '가이드', '인터뷰'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>@prague</td>\n",
       "      <td>39</td>\n",
       "      <td>['프라하', '체코', '유럽여행']</td>\n",
       "      <td>['프라하', '체코', '유럽여행', '여행', '체코여행', '까를교', '유럽...</td>\n",
       "      <td>['프라하', '유럽여행', '체코', '유럽여행', '프라하', '체코', '프라...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>@tilltue</td>\n",
       "      <td>39</td>\n",
       "      <td>['IT', 'iOS', '개발']</td>\n",
       "      <td>['IT', 'iOS', '개발', '이벤트', '테스트', 'event', '프로...</td>\n",
       "      <td>['테스트코드', '테스트', 'IT', 'IT', 'iOS', 'IT', '테스트...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>@moeanee</td>\n",
       "      <td>39</td>\n",
       "      <td>['에세이', '사랑', '감성']</td>\n",
       "      <td>['에세이', '사랑', '감성', '생각', '일상', '삶', '브런치X어라운드...</td>\n",
       "      <td>['마음', '독서', '에세이', '브런치X어라운드', '생각', '에세이', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        writer_id  page_num           keyword_list  \\\n",
       "0        @bookfit      4106     ['성공', '행복', '인생']   \n",
       "1       @wikitree      3192   ['영화', '뉴스', '연합뉴스']   \n",
       "2      @jordan777      2797    ['중국', '미국', '트럼프']   \n",
       "3      @hitchwill      2115   ['국내여행', '영화', '여행']   \n",
       "4        @tenbody      1759   ['다이어트', '운동', '건강']   \n",
       "...           ...       ...                    ...   \n",
       "3995  @starshines        39     ['영화', '사랑', '전쟁']   \n",
       "3996   @jeolmiing        39  ['독서', '독서모임', '인터뷰']   \n",
       "3997      @prague        39  ['프라하', '체코', '유럽여행']   \n",
       "3998     @tilltue        39    ['IT', 'iOS', '개발']   \n",
       "3999     @moeanee        39    ['에세이', '사랑', '감성']   \n",
       "\n",
       "                                        keyword_list_20  \\\n",
       "0     ['성공', '행복', '인생', '부동산', '여행', '창업', '사랑', '생...   \n",
       "1     ['영화', '뉴스', '연합뉴스', '경찰', '다이어트', '사진', '여행',...   \n",
       "2     ['중국', '미국', '트럼프', '부동산', '주식', '투자', '구글', '...   \n",
       "3     ['국내여행', '영화', '여행', '여행정보', '음식', '사랑', '소설',...   \n",
       "4     ['다이어트', '운동', '건강', '스트레칭', '근육', '뱃살', '요가',...   \n",
       "...                                                 ...   \n",
       "3995  ['영화', '사랑', '전쟁', '범죄영화', '픽사', '리뷰', '한국영화',...   \n",
       "3996  ['독서', '독서모임', '인터뷰', '사랑', '모임', '행복', '생각', ...   \n",
       "3997  ['프라하', '체코', '유럽여행', '여행', '체코여행', '까를교', '유럽...   \n",
       "3998  ['IT', 'iOS', '개발', '이벤트', '테스트', 'event', '프로...   \n",
       "3999  ['에세이', '사랑', '감성', '생각', '일상', '삶', '브런치X어라운드...   \n",
       "\n",
       "                                               keywords  \n",
       "0     ['창업', '비즈니스', '문제', '경제', '살림살이', '경제학', '미세먼...  \n",
       "1     ['지휘관', '장교', '청계천', '서울', 'IT', '번호', '중소기업',...  \n",
       "2     ['석유에너지', '베네수엘라', '경제', '일자리', '청년실업', '저출산',...  \n",
       "3     ['국내여행', '한옥', '청양', '여행', '가을', '코스모스', '감귤농장...  \n",
       "4     ['운동', '근육', '다이어트', '운동', '뱃살', '다이어트', '운동',...  \n",
       "...                                                 ...  \n",
       "3995  ['영화', '저니스엔드', '전쟁', '영화', '하정우', '민주주의', '히트...  \n",
       "3996  ['독서', '일상', '인터뷰', '후기', '독서모임', '가이드', '인터뷰'...  \n",
       "3997  ['프라하', '유럽여행', '체코', '유럽여행', '프라하', '체코', '프라...  \n",
       "3998  ['테스트코드', '테스트', 'IT', 'IT', 'iOS', 'IT', '테스트...  \n",
       "3999  ['마음', '독서', '에세이', '브런치X어라운드', '생각', '에세이', '...  \n",
       "\n",
       "[4000 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer_4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_following_author_keywords(id):\n",
    "    temp = []\n",
    "    follow_list = list(following.loc[following['id'] == id, 'following_list'])[0]\n",
    "    for author in follow_list:\n",
    "        temp.append(list(writer_4000.loc[writer_4000['writer_id'] == author, 'keywords'])[0])\n",
    "    result = temp[0]\n",
    "    for i in range(1,len(temp)):\n",
    "        result += temp[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['그림일기', '부산외대컴퓨터수리', '현진컴퓨터', '모험', '희극', '비극', '로건', '울버린', '엑스맨', 'Instagram', '무책임', '페리', '에너지', '거절', '실패', '오라', '당신', '하늘', '슬픔', '생각', '당신', '비가', '당신', '본격광고만화', '토스터', '기억', '햇살', '바닥', '초록', '당신', '제주', '협재바다', '바다', '꼬옥', '그늘', '평생', '햇살', '시간', '새해', '세상', '항해', '햇살', '바다', '겨울', '당신', '행복', '매일', '로켓', '행복', '잠금화면', '온도', '화면', '웃음', '비결', '기분', '꽃길', '걸음', '당신', '페리', '제주', '시작', '시간', '페리', '제주동쪽', '제주', '풍림다방', '제주', '협재', '미니', '금빛', '순간', '당신', '조각', '욕심', '마음', '유리', '당신', '생각', '페리', '이모티콘', '자가증식', '영화', '라라랜드', '공중', 'BMW', '페리', '메일', '손짓', '바닥', '점점', '메리크리스마스', '크리스마스', '당신', '안녕', '당신', '다음', '페리', '여행', '출발', '순간', '페리', '페리', '부탁', '올해', '버프툰', '웹툰', '웹툰', '공유', '버프', '버프툰', '하루', '일상', '웹툰', '공유', '버프툰', '웹툰', '거리', '웹툰', '버프툰', '구독', '텀블벅', '시간', '버프툰', '일상', '구원', '아이폰', '겨울', '감정가게', '페리', '감정가게', '페리', '당신', '메리크리스마스', '배경화면', '잠금화면', '잠금화면', '감정가게', '페리', '잠금화면', '아이폰', '감정가게', '페리', '안녕', '감정가게', '아이폰', '잠금화면', '감정가게', '텀블벅', '펀딩', '시간', 'love', '페리', '다이어리', '매일', '텀블벅', '해피메리추석', '명절', '파도', '마음', '저녁', '파도', '에라', '물보라', '요즘', '하늘', '색깔', '사랑', '온도', '햇살', '해피메리추석', '바람', '운전', '다이어리', '시간', '기록', '생일주간', '기록', '시간', '아이폰', '부산외대컴퓨터수리', '잠금화면', '감정가게', '페리', '아이폰X', '스마트폰', '아이폰', '잠금화면', '그림일기', '사랑', '콘서트', '공연', '페리', '어제', '여름', '제주', '하루', '오후', '제주', '하루', '햇살', '유리', '감정가게', '감정', '페리', '파도', '감정', '심연', '감정가게', '페리', '감정', '제주카페', '제주여행', '커피', '고양이', '제주', '강아지', '아이폰', '잠금화면', '안드로이드', '아이폰', '잠금화면', '순간', '방향', '감사', '하늘', '제주', '비행', '요즘파란하늘', '공기질', '페리', '걸음', '무엇', '사랑', '향기', '예감', '커피', '위로', '감정가게', '커피', '여름', '콘서트', '폼텍', '합정', '제주도', '여행', '페리', '바다', '공간', '비가', '계절', '속삭임', '빗소리', '아이폰', '안드로이드', '잠금화면', '안드로이드', '아이폰', '잠금화면', '연재', '웹툰', '고양이', '고양이', '우연', '만화', '계획', '선택', '생각', '커피', '빗소리', '음악', '웹툰', '고양이', '11번가', '본격광고만화', '보조배터리', '당신', '가슴', '걸음', '11번가', '본격광고만화', '페리캐릭터', '당신', '이야기', '11번가', '본격광고만화', '완판', '당신', '페리', '정답', '11번가', '본격광고만화', '완판', '풍경', '무엇', '사랑', '페리', '상상', '11번가', '잠금화면', '벚꽃', '당신', '잠금화면', '잠금화면', '잠금', '기분', '웹툰', '원고', '만화', '잠금화면', '잠금', '매일매일', '이별', '영원', '기한', '의자', '골목', '애정', 'BMW', '심장', '쿠페', '꽃잎', '욕심', '당신', 'BMW', '미래', '비엠', '입김', '가을', '온도', '스토리펀딩', '기록', '페리', '계절', '가을', '당신', '걸음', '다음', '하루', '조각', '당신', '머릿속', '반짝이', '순간', '온도', '하늘', '기억', '하늘', '사진일기', '고양이', '평화', '시간', '햇살', '페리', '아침사이', '새벽', '프로급체', '자격증', '페리', 'BMW', '자동차', '기억', '시간', '당신', '반려동물과새로운시작', '공유', '댓글', '웹툰', '반려동물과새로운시작', '고양이', '만화', '인연', '버프툰', '상처', '웹툰', '사랑', '햇살', '행복', '웹툰', '반려동물', '웹툰', '구독', '공유', '구독', '웹툰', '반려동물', '고양이', '행복', '당신', '순간', '그때', '사람', '당신', '바다', '태도', '파도', '샤워', '오후', '멈춤', '계절', '겨울', '감정가게', '부산외대컴퓨터수리', '현진컴퓨터', '다이어리', '시간', '기록', '감정가게', '페리', '풍경', '겨울', '감정가게', '페리', '다이어리', '기록', '시간', '감정가게', '페리', '감정', '그림일기', '카툰', '웹툰', '감정가게', '페리', '감정', '웹툰', '버프', '마음', '웹툰', '반려동물과새로운시작', '웹툰', '마음', '버프툰', '연재', '페리', '외로움', '감정가게', '커피', '기억', '시간', '기록', '감정가게', '페리', '인생', '감정가게', '기분', '페리', '감정가게', '페리', '시간', '감정가게', '페리', '감정', '생각', '감정가게', '페리', '감정가게', '페리', '이소라', '웹툰', '연재', '일요일', '사진기록일기', '만화', '웹툰', '버프툰', '웹툰', '수술', '구독', '공유', '마음', '구독', '초록', '충전', '휴식', '다행', '당신', '후회', '커피', '얼음', '당신', '무지개', '행복', '곳곳', '회색', '외로움', '당신', '기억', '색깔', '추억', '우산', '당신', '동네', '무지개', '주위', '색깔', '반려동물과새로운시작', '페리', '버프툰', '페리', '연재', '버프툰', '공기', '기억', '그때', '구원', '시작', '인생', '마감', '당신', '다음', '씨앗', '행복', '변화', '아스팔트', '생명', '계속', '폐허', '통행', '불편', '햇볕', '걸음', '당신', '산책', '감정가게', '페리', 'Instagram', '풍선', '유행', '그림일기', '골목', '산책', '계절', '경찰버스', '차벽', '안국', '머릿속', '지분', '당신', '월요일', '하루', '당신', '본격투표독려만화', '투표', '선거', '온도', '당신', '거리', '화양연화', '인생', '공연', '파란', '신호', '순간', '며칠', '당신', '순간', '시간', '생각', '당신', '겨울기억', '그때', '겨울', '일시정지', '여운', '장면', '당신', '원래', '인생', '골목', '행복', '색깔', '온도', '당신', '가슴', '커피', '카페', '행복', '당신', '다음', '손잡이', '페리', '이불', '종종', '커피', '당신', '이야기', '명동', '순간', '그때', '감정', '걱정', '사람', '우주', '당신', '오후', '마음', '미련', '장소', '마음', '당신', '주위', '마음', '사람', 'YouTube', '어린이', '마음', '당신', '분류', '고민', '해결', '웃음', '당신', '씨앗', '컨디션', '바람', '기분', '날개', '하늘', '당신', '페리', '버프툰', '연재', '걸음', '안녕', '행복', '웹툰', '버프툰', 'Instagram', '해안도로', '제주', '협재해변', '제주', '다람쥐식탁', '월령선인장마을', '버프툰', '일상', '시간', '일상', '버프툰', 'Instagram', '버프툰', '일상', '집사', '사람', '안녕', '겨울', '방향', '세상', '창밖', '호기심', '선물', '한동안', '감정가게', '감정', '페리', '짝사랑', '연애', '사랑', '스위치', '하루', '바다', '당신', '걸음', '카페', '인생', '커피', '웃음', '당신', '소리', '날개', '좌절', '순간', '명절', '추석', '당신', '웃음', '출구', '발견', '웹툰', '버프툰', '구독', '걸음', '정화', '가치', '공중전화부스', '그때', '카드', '불빛', '눈물', '당신', '시간', '온도', '당신', '합주', '인생', '독주', '커튼', '시작', '다음', '인생사', '그때', '온도', '에너지', '하루', '시간', '시작', '두려움', '설렘', '제주여행', '무지개', '행복', '근황', '일상', '만화가', '물음', '기억', '당신', '연재', '펀딩', '시간', '추석', '잔소리', '유턴', '위로', '그날', '하늘', '자리', '세월', '당신', '웹툰', '브런치', '연재', '다이어리', '하루하루', '기록', 'web', '만화', '브런치', '우주', '당신', '생각', '마음속', '순간', '생각', '불빛', '관계', '행복', '절반', '계획', '행복', '월요일', '당신', '커피', '당신', '방향', '순간', '당신', '생각', '공연', '사랑', '기억', '당신', '위로', '방향', '하나', '당신', '나이', '시간', '부유', '햇살', '대륙', '햇살', '바닥', '당신', '파도', '타자', '당신', '폐허', '마음', '당신', '하루', '순간', '보랏빛', '가게', '중간중간', '당신', '커피', '행복', '아메리카노', '콘서트', '공연', '페리', '영화', '나홍진', '장르', '먹구름', '하늘', '파란', '콘서트', '공연', '페리', '마음속', '평화', '요즘', '콘서트', '이벤트', '카카오브런치', '그림', '완성', '과정', '당신', '꽃잎', '마음', '위로', '공연', '당신', '다음', '내일모레', '내일', '공연', '동작', '하나', '손바닥']['인터뷰', '작가', '아나운서', '작가', '인터뷰', '브런치', '브런치', '스웨덴', '토크콘서트', '철학', '인터뷰', '작가', '브런치', '공모전', '출판', '브런치', '브런치북', '출간', '작가', '브런치X빨강머리앤', '빨강머리앤', '출판', '작가', '브런치', '에디터', '맞춤법', '브런치', '작가', '인터뷰', '음식덕후', '음식문화', '음식', '작가', '인터뷰', '브런치', '콜라보레이션', '오보이', '동물', '브런치', '작가', '인터뷰', '교육', '작가', '인터뷰', '브런치볼드저널', '볼드저널', '브런치', '작가', '브런치', '브런치북', '작가', '이음', '인터뷰', '브런치', '작가', '매거진', '브런치', '브런치', '브런치북', '공모전', '청춘', '작가', '인터뷰', '브런치', '토크콘서트', '브런치북', '출간', '프로젝트', '공유', '페이스북', '카카오톡', '소방관', '작가', '인터뷰', '퇴사', '작가', '인터뷰', '인간과동물', '작가', '인터뷰', '브런치북', '출간', '프로젝트', '브런치', '콜라보레이션', '프로젝트', '브런치북', '출간', '공모전', '브런치', '시사회', '브런치무비패스', '이벤트', '이모티콘', '브런치', '브런치', '수상작품', '작가', '동화작가', '작가', '인터뷰', '브런치', '나우', '키워드', '브런치', '콜라보레이션', '당선작', '여행', '론리플래닛', '콜라보레이션', '에세이', '작가', '인터뷰', '여행', '론리플래닛', '콜라보레이션', '브런치', '작가', '제안', '설문', '이벤트', '카카오프렌즈', '작가', '인터뷰', '축구', '직장생활', '작가', '인터뷰', '육아', '작가', '인터뷰', '브런치', '키워드', '에디터', '브런치', '토크콘서트', '아카이브', 'like', '브런치북', '출간', '당선작', '브런치', '토크콘서트', '드로잉', '이용약관', '개인정보보호', '안내', '에디터', '사진편집', '편집기', '브런치X볼드저널', '브런치', '볼드저널', '수상작가', '브런치북', '출판', '브런치', '연재', '작품', '반려동물', '동물', 'Daum', '개인정보보호', '안내', '수상작', '브런치북', '작품', '만화', '작가', '인터뷰', '브런치', '책방', '독서', '개인정보', '개인정보보호', '취급방침', '브런치', '게시글', '개편', '모터사이클', '작가', '인터뷰', '작가', '브런치', '인터뷰', '웹툰', '작가', '인터뷰', '브런치', '개편', '안내', '바닐라로맨스', '인터뷰', '연애', '영화', '브런치', '시사회', '출판', 'POD', '출간', '브런치북', '작가', '출판', '브런치', '추천', '브런치앱', '트래블라인싱가포르', '싱가포르', '여행', '작가', '브런치', '공모전', '브런치', '동영상', '점검', '작가인터뷰', '신동진', '브런치', '여행', '싱가포르', '브런치', '브런치북', '출간', '프로젝트', '브런치', '작가', '글쓰기', '이우성', '토크콘서트', '브런치', '브런치', '토크콘서트', '드로잉', '이우성', '토크콘서트', '브런치', '브런치', '매거진', '안내', '브런치', '작가', '안내', '브런치', '에디터', '안내', '링크', '에디터', '동영상', '취미', '작가', '인터뷰', '자기계발', '백화점', '인터뷰', '브런치', '출간', '인터뷰', '독서', '브런치', '인터뷰', '브런치', '에디터', '글쓰기', '브런치', '이병률', '인터뷰', '론리플래닛', '콜라보레이션', '당선작', '브런치', '점검', '안내', '브라질', '작가', '인터뷰', '브런치', '개편', '글쓰기', '작가', '브런치', '소설', '글쓰기', '브런치', '브런치어라운드', '콜라보', '어라운드', '인생', '작가', '인터뷰', '이벤트', '브런치', '기념', '브런치', '콜라보레이션', '오보이', '그림일기', '인터뷰', '작가', '브런치', '출간', '브런치북', '카카오', '브런치', '클래스', '인간관계', '작가', '인터뷰', '에세이', '작가', '토크콘서트', '작가', '브런치', '검색', '브런치', '작가', '프로필', '수상작', '브런치북', '출판', '작가', '캘리그래피', '토크콘서트', '이유미', '토크콘서트', '에세이', '브런치', '브런치무비패스', '시사회', '브런치', '페이스북', '댓글', '프로필', '안내', '이직', '해외취업', '싱가포르', '작가', '사랑', '인터뷰', '브런치', '토크콘서트', '이벤트', '강연', '브런치', '콘텐츠', '작가', '인터뷰', '베스트셀러', '작가', '인터뷰', '파리', '캘리그래피', '토크콘서트', '브런치', '브런치북', '멘토링', '브런치', '브런치', '작가', '만남', '전시회', '일러스트', '브런치북', '요리이야기', '작가', '인터뷰', '출판', '브런치북', '수상작', '출판사', '브런치북', '멘토', '영화', '브런치무비패스', '시사회', '브런치', '책방', '출판', '강연', '인터뷰', '작가', '영화', '브런치무비패스', '시사회', '브런치X어라운드', '콜라보레이션', '어라운드', '브런치북', '출간', '작가', '강연', '브런치', '작가', '브런치', '작가', '인터뷰', '댓글', '브런치앱', '브런치', '매거진', '이미지', '캡션', '작가', '인터뷰', '브랜드']\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_following_author_keywords('#901985d8bc4c481805c4a4f911814c4a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unix 시간 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['upload_time'] = pd.to_datetime(metadata['reg_ts']/1000, unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시간기준으로 metadata 나누기\n",
    "### 2019 이전 / 2019 이후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['upload_year'] = metadata['upload_time'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magazine_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>keyword_list</th>\n",
       "      <th>display_url</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>reg_ts</th>\n",
       "      <th>article_id</th>\n",
       "      <th>id</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>upload_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8982</td>\n",
       "      <td>@bookdb</td>\n",
       "      <td>사진으로 옮기기에도 아까운, 리치필드 국립공원</td>\n",
       "      <td>[여행, 호주, 국립공원]</td>\n",
       "      <td>https://brunch.co.kr/@bookdb/782</td>\n",
       "      <td>세상 어디에도 없는 호주 Top 10</td>\n",
       "      <td>1474944427000</td>\n",
       "      <td>782</td>\n",
       "      <td>@bookdb_782</td>\n",
       "      <td>2016-09-27 02:47:07</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12081</td>\n",
       "      <td>@kohwang56</td>\n",
       "      <td>[시] 서러운 봄</td>\n",
       "      <td>[목련꽃, 아지랑이, 동행]</td>\n",
       "      <td>https://brunch.co.kr/@kohwang56/81</td>\n",
       "      <td></td>\n",
       "      <td>1463092749000</td>\n",
       "      <td>81</td>\n",
       "      <td>@kohwang56_81</td>\n",
       "      <td>2016-05-12 22:39:09</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@hannahajink</td>\n",
       "      <td>무엇을 위해</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://brunch.co.kr/@hannahajink/4</td>\n",
       "      <td>무엇 때문에</td>\n",
       "      <td>1447997287000</td>\n",
       "      <td>4</td>\n",
       "      <td>@hannahajink_4</td>\n",
       "      <td>2015-11-20 05:28:07</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16315</td>\n",
       "      <td>@bryceandjuli</td>\n",
       "      <td>싫다</td>\n",
       "      <td>[감정, 마음, 위로]</td>\n",
       "      <td>https://brunch.co.kr/@bryceandjuli/88</td>\n",
       "      <td></td>\n",
       "      <td>1491055161000</td>\n",
       "      <td>88</td>\n",
       "      <td>@bryceandjuli_88</td>\n",
       "      <td>2017-04-01 13:59:21</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29363</td>\n",
       "      <td>@mijeongpark</td>\n",
       "      <td>Dubliner#7</td>\n",
       "      <td>[유럽여행, 더블린, 아일랜드]</td>\n",
       "      <td>https://brunch.co.kr/@mijeongpark/34</td>\n",
       "      <td>#7. 내 친구의 집은 어디인가</td>\n",
       "      <td>1523292942000</td>\n",
       "      <td>34</td>\n",
       "      <td>@mijeongpark_34</td>\n",
       "      <td>2018-04-09 16:55:42</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   magazine_id        user_id                      title       keyword_list  \\\n",
       "0         8982        @bookdb  사진으로 옮기기에도 아까운, 리치필드 국립공원     [여행, 호주, 국립공원]   \n",
       "1        12081     @kohwang56                  [시] 서러운 봄    [목련꽃, 아지랑이, 동행]   \n",
       "2            0   @hannahajink                     무엇을 위해                 []   \n",
       "3        16315  @bryceandjuli                         싫다       [감정, 마음, 위로]   \n",
       "4        29363   @mijeongpark                 Dubliner#7  [유럽여행, 더블린, 아일랜드]   \n",
       "\n",
       "                             display_url             sub_title         reg_ts  \\\n",
       "0       https://brunch.co.kr/@bookdb/782  세상 어디에도 없는 호주 Top 10  1474944427000   \n",
       "1     https://brunch.co.kr/@kohwang56/81                        1463092749000   \n",
       "2    https://brunch.co.kr/@hannahajink/4                무엇 때문에  1447997287000   \n",
       "3  https://brunch.co.kr/@bryceandjuli/88                        1491055161000   \n",
       "4   https://brunch.co.kr/@mijeongpark/34     #7. 내 친구의 집은 어디인가  1523292942000   \n",
       "\n",
       "   article_id                id         upload_time  upload_year  \n",
       "0         782       @bookdb_782 2016-09-27 02:47:07         2016  \n",
       "1          81     @kohwang56_81 2016-05-12 22:39:09         2016  \n",
       "2           4    @hannahajink_4 2015-11-20 05:28:07         2015  \n",
       "3          88  @bryceandjuli_88 2017-04-01 13:59:21         2017  \n",
       "4          34   @mijeongpark_34 2018-04-09 16:55:42         2018  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_metadata = metadata[metadata['upload_year'] < 2019]\n",
    "before_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magazine_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>keyword_list</th>\n",
       "      <th>display_url</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>reg_ts</th>\n",
       "      <th>article_id</th>\n",
       "      <th>id</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>upload_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>39727</td>\n",
       "      <td>@hukho</td>\n",
       "      <td>같은 물건의 다른 삶</td>\n",
       "      <td>[패션, 에세이, 경제]</td>\n",
       "      <td>https://brunch.co.kr/@hukho/247</td>\n",
       "      <td>MD의 꽃점</td>\n",
       "      <td>1551798000000</td>\n",
       "      <td>247</td>\n",
       "      <td>@hukho_247</td>\n",
       "      <td>2019-03-05 15:00:00</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40763</td>\n",
       "      <td>@seesawyou</td>\n",
       "      <td>여행 단상 1</td>\n",
       "      <td>[단상, 여행, 생각]</td>\n",
       "      <td>https://brunch.co.kr/@seesawyou/130</td>\n",
       "      <td>(6) 나는 왜 떠나왔는가  # 2</td>\n",
       "      <td>1547185083000</td>\n",
       "      <td>130</td>\n",
       "      <td>@seesawyou_130</td>\n",
       "      <td>2019-01-11 05:38:03</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39865</td>\n",
       "      <td>@haninorway19</td>\n",
       "      <td>엄마도 취향이 있다</td>\n",
       "      <td>[엄마, 취향, 효도]</td>\n",
       "      <td>https://brunch.co.kr/@haninorway19/103</td>\n",
       "      <td>엄마가 좋아하고 싫어하는 걸 알게 된 기쁜 순간</td>\n",
       "      <td>1553232472000</td>\n",
       "      <td>103</td>\n",
       "      <td>@haninorway19_103</td>\n",
       "      <td>2019-03-22 05:27:52</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40763</td>\n",
       "      <td>@seesawyou</td>\n",
       "      <td>세계여행, 막상 해보니 어때? 행복해? / 체코 프라하</td>\n",
       "      <td>[세계여행, 여행, 행복]</td>\n",
       "      <td>https://brunch.co.kr/@seesawyou/133</td>\n",
       "      <td>(7) 행복에 대하여  # 1</td>\n",
       "      <td>1547333801000</td>\n",
       "      <td>133</td>\n",
       "      <td>@seesawyou_133</td>\n",
       "      <td>2019-01-12 22:56:41</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>42456</td>\n",
       "      <td>@jerad</td>\n",
       "      <td>‘팀워크’보다 앞서는 ‘개인기’는 없다</td>\n",
       "      <td>[팀워크, 성과, 개인기]</td>\n",
       "      <td>https://brunch.co.kr/@jerad/200</td>\n",
       "      <td></td>\n",
       "      <td>1551366000000</td>\n",
       "      <td>200</td>\n",
       "      <td>@jerad_200</td>\n",
       "      <td>2019-02-28 15:00:00</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    magazine_id        user_id                           title  \\\n",
       "10        39727         @hukho                     같은 물건의 다른 삶   \n",
       "14        40763     @seesawyou                         여행 단상 1   \n",
       "19        39865  @haninorway19                      엄마도 취향이 있다   \n",
       "21        40763     @seesawyou  세계여행, 막상 해보니 어때? 행복해? / 체코 프라하   \n",
       "25        42456         @jerad           ‘팀워크’보다 앞서는 ‘개인기’는 없다   \n",
       "\n",
       "      keyword_list                             display_url  \\\n",
       "10   [패션, 에세이, 경제]         https://brunch.co.kr/@hukho/247   \n",
       "14    [단상, 여행, 생각]     https://brunch.co.kr/@seesawyou/130   \n",
       "19    [엄마, 취향, 효도]  https://brunch.co.kr/@haninorway19/103   \n",
       "21  [세계여행, 여행, 행복]     https://brunch.co.kr/@seesawyou/133   \n",
       "25  [팀워크, 성과, 개인기]         https://brunch.co.kr/@jerad/200   \n",
       "\n",
       "                     sub_title         reg_ts  article_id                 id  \\\n",
       "10                      MD의 꽃점  1551798000000         247         @hukho_247   \n",
       "14         (6) 나는 왜 떠나왔는가  # 2  1547185083000         130     @seesawyou_130   \n",
       "19  엄마가 좋아하고 싫어하는 걸 알게 된 기쁜 순간  1553232472000         103  @haninorway19_103   \n",
       "21            (7) 행복에 대하여  # 1  1547333801000         133     @seesawyou_133   \n",
       "25                              1551366000000         200         @jerad_200   \n",
       "\n",
       "           upload_time  upload_year  \n",
       "10 2019-03-05 15:00:00         2019  \n",
       "14 2019-01-11 05:38:03         2019  \n",
       "19 2019-03-22 05:27:52         2019  \n",
       "21 2019-01-12 22:56:41         2019  \n",
       "25 2019-02-28 15:00:00         2019  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_metadata = metadata[metadata['upload_year'] >= 2019]\n",
    "after_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 유사도 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 독자가 읽은 글 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 분석에 필요한 패키지를 불러온다\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer_4000 = pd.read_csv(directory + 'writer_4000most3_keyword_keywords.csv', index_col=0)\n",
    "# 작가 데이터 vectorization\n",
    "writer_key = []\n",
    "\n",
    "for i in range(4000):\n",
    "    writer_key.append(' '.join(eval(writer_4000['keywords'][i])))\n",
    "    \n",
    "corpus = writer_key\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus).todense()\n",
    "pd.DataFrame(X)\n",
    "\n",
    "\n",
    "def reader_read(i):    \n",
    "    # 독자데이터 vectorization\n",
    "    read_key = user['keyword_list']\n",
    "    read_key[i] = eval(read_key[i])\n",
    "    read1 = ' '.join(read_key[i])\n",
    "    reader = vectorizer.transform([read1]).todense()\n",
    "    \n",
    "    # Cosine similarity 계산\n",
    "    cosine_similarity(reader, X)\n",
    "    result = cosine_similarity(reader, X)\n",
    "    \n",
    "    # 결과 값 도출\n",
    "    global writer_4000\n",
    "    writer_4000['read_sim'] = result[0]\n",
    "    writer_4000.sort_values(by='read_sim', ascending=False)\n",
    "    writer_4000 = writer_4000.sort_values(by='read_sim', ascending=False)\n",
    "    writer_top3 = writer_4000.head(3)\n",
    "    writer_results = writer_top3['writer_id'].tolist()\n",
    "    print(\"%s님께 추천드리는 작가는 %s, %s, %s 입니다.\"%(user['user_id'][i], writer_results[0], writer_results[1], writer_results[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.24 GiB for an array with shape (4000, 75085) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-7dd95a4ff430>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreader_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-6c1e54d5eb23>\u001b[0m in \u001b[0;36mreader_read\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Cosine similarity 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_normalized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m         \u001b[0mY_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m     K = safe_sparse_dot(X_normalized, Y_normalized.T,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[0;32m   1902\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'%d' is not a supported axis\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1904\u001b[1;33m     X = check_array(X, accept_sparse=sparse_format, copy=copy,\n\u001b[0m\u001b[0;32m   1905\u001b[0m                     estimator='the normalize function', dtype=FLOAT_DTYPES)\n\u001b[0;32m   1906\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmay_share_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.24 GiB for an array with shape (4000, 75085) and data type float64"
     ]
    }
   ],
   "source": [
    "reader_read(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 독자가 구독한 작가 기반 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_user_following_author_keywords(id):\n",
    "#     temp = []\n",
    "#     follow_list = list(following.loc[following['id'] == id, 'following_list'])[0]\n",
    "#     for author in follow_list:\n",
    "#         temp.append(list(writer_4000.loc[writer_4000['writer_id'] == author, 'keywords'])[0])\n",
    "#     result = temp[0]\n",
    "#     for i in range(1,len(temp)):\n",
    "#         result += temp[i]\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_following_author_keywords(id):\n",
    "    temp = []\n",
    "    follow_list = list(following.loc[following['id'] == id, 'following_list'])[0]\n",
    "    for author in follow_list:\n",
    "        append_list = writer_4000.loc[writer_4000['writer_id'] == author, 'keywords']\n",
    "        if len(append_list) > 0:\n",
    "            append_list = list(append_list)[0]\n",
    "            temp.append(append_list)\n",
    "\n",
    "    result = temp[0]\n",
    "    for i in range(1,len(temp)):\n",
    "        result += temp[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writer_4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader_follow(i):\n",
    "    global writer_4000\n",
    "    \n",
    "    # 독자데이터 vectorization\n",
    "    list_t = get_user_following_author_keywords(following['id'][i])\n",
    "    read_to_list = [l + \"]\" for l in list_t.split(\"]\")][:-1]\n",
    "    read_to_list = [eval(l) for l in read_to_list]\n",
    "    read2 =  ' '.join(read_to_list[0])\n",
    "    reader2 = vectorizer.transform([read2]).todense()\n",
    "    \n",
    "    # Cosine similarity 계산\n",
    "    result_follow = cosine_similarity(reader2, X)\n",
    "    \n",
    "    # 결과 값 도출\n",
    "    writer_4000['follow_sim'] = result_follow[0]\n",
    "    writer_4000 = writer_4000.sort_values(by='follow_sim', ascending=False)\n",
    "    writers_top3 = writer_4000.head(3)\n",
    "    writers_results = writers_top3['writer_id'].tolist()\n",
    "    \n",
    "    return writers_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writers_results = reader_follow(1)\n",
    "writers_results\n",
    "print(\"%s님께서 팔로우하시는 작가 기반으로 추천드리는 작가는 %s, %s입니다.\"%(following['id'][1], writers_results[0], writers_results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(writers_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writers_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추천받은 작가기반 글 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df = after_metadata.loc[after_metadata['user_id'].isin(writers_results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoomd_article(recommend_authors, i):\n",
    "    global article_df\n",
    "    user_id = following['id'][i]\n",
    "\n",
    "    reader = get_user_following_author_keywords(user_id)\n",
    "    reader = reader[1:-1].replace('\\'','').replace(',','')\n",
    "    \n",
    "    articles = list(after_metadata.loc[after_metadata['user_id'].isin(recommend_authors)]['keyword_list'])\n",
    "    \n",
    "    article_key = []\n",
    "\n",
    "    for i in range(len(articles)):\n",
    "        article_key.append(' '.join(eval(str(articles[i]))))\n",
    "        \n",
    "    corpus = article_key\n",
    "    vectorizer = TfidfVectorizer()  # TfidfVectorizer() 객체 변수 생성\n",
    "    X = vectorizer.fit_transform(corpus).todense()\n",
    "    \n",
    "    reader2 = vectorizer.transform([reader]).todense()\n",
    "    \n",
    "    pd.DataFrame(X) # np.array or np.matrix => pd.DataFrame\n",
    "    \n",
    "    result = cosine_similarity(reader2, X)\n",
    "    article_df['read_sim'] = result[0]\n",
    "    article_df = article_df.sort_values(by='read_sim', ascending=False)\n",
    "    \n",
    "    return article_df.iloc[0]['title']\n",
    "    \n",
    "    \n",
    "    return reader\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writers_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "article = recoomd_article(writers_results, 1)\n",
    "print(\"%s님께서 추천 받은 작가 중에서 취향에 맞는 글은 \\'%s\\' 입니다.\"%(following['id'][1], article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
